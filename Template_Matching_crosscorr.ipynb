{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "%matplotlib widget\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import matplotlib.cm as cm\n",
    "from Funciones_auxiliares import Mat_to_dataframe,see_teams,get_cluster_indexs,plot_branch,plot_teams,find_mix\n",
    "from scipy import cluster\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.signal import correlate\n",
    "\n",
    "import scipy as sp\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85cf4002c394b78b5427ddc39f47f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "plt.clf()\n",
    "plt.close()\n",
    "data = pd.read_pickle('Datos/PCCIBNMZc')\n",
    "data['Mean'] = data.Bulk.apply(lambda row: np.mean(row,axis = 0))\n",
    "data['Mean'] = (data['Mean'] - data.Mean.apply(lambda row:np.mean(row)))/data.Mean.apply(lambda row:np.std(row))\n",
    "del data['Bulk']\n",
    "Initial = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos en Test y Train por sessiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "115\n",
      "167\n",
      "118\n",
      "314\n",
      "82\n",
      "85\n",
      "116\n",
      "356\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "T = True\n",
    "while T:\n",
    "    Sessions_list = data.PatientExperiment.unique()\n",
    "    select_random_sessions = np.random.choice(Sessions_list,(10,6), replace = False)\n",
    "    Dfs = {}\n",
    "    for i,sessions in enumerate(select_random_sessions):\n",
    "        Dfs[i] = data[data.PatientExperiment.isin(sessions)]\n",
    "    lenghts = np.array([len(i) for i in Dfs.values()])\n",
    "    if np.all(lenghts > 80): T = False\n",
    "    \n",
    "for key,values in Dfs.items():\n",
    "    print(len(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No tengo que entrenar nada, asumimos que el template matching para train es perfecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distancia Mahalanobis, necesitamos computar la matriz de covarianza. Dado que asumimos que hay 64 variables la matriz de covarianza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714 856\n"
     ]
    }
   ],
   "source": [
    "def Train_test_noise(data):\n",
    "    Sessions_list = data.PatientExperiment.unique()\n",
    "    select_random_sessions = np.random.randint(0, len(Sessions_list), size=int(len(Sessions_list)/2))\n",
    "    Train_list = Sessions_list[select_random_sessions]\n",
    "    Train = data[data.PatientExperiment.isin(Train_list)]\n",
    "    Test = data[~data.PatientExperiment.isin(Train_list)]\n",
    "    Train.reset_index(inplace = True,drop = True)\n",
    "    Test.reset_index(inplace = True,drop = True)\n",
    "    \n",
    "    df_train = Train.copy()\n",
    "    df_test = Test.copy()\n",
    "    \n",
    "    Noise = df_train[df_train.bNoise == 1]\n",
    "    Neuron = df_train[df_train.bNoise == 0]\n",
    "    MU = df_train[df_train.bNoise == 2]\n",
    "\n",
    "    df_train = pd.concat([Neuron,MU,Noise], ignore_index= True, sort = False)\n",
    "    t = df_train[df_train.bNoise == 1].index[0]\n",
    "\n",
    "    Noise = df_test[df_test.bNoise == 1]\n",
    "    Neuron = df_test[df_test.bNoise == 0]\n",
    "    MU = df_test[df_test.bNoise == 2]\n",
    "\n",
    "    df_test = pd.concat([Neuron,MU,Noise], ignore_index= True, sort = False)\n",
    "    t2 = df_test[df_test.bNoise == 1].index[0]\n",
    "\n",
    "    Cov = np.array(df_train.Mean.to_list()).T\n",
    "    Cov = np.cov(Cov)\n",
    "    Cov.shape\n",
    "    \n",
    "    return df_train,df_test,t,t2\n",
    "\n",
    "df_train,df_test,t,t2 = Train_test_noise(data)\n",
    "print(len(df_train),len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testeamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "def compute_dist(df_test,df_train):\n",
    "    f = lambda x,y:correlate(x,y,'valid')[0]\n",
    "    df = pd.concat([df_train,df_test],ignore_index=True,sort = True)\n",
    "    r = len(df_train)\n",
    "    s = len(df_test)\n",
    "    Dist = pd.DataFrame(squareform(pdist(np.array(df.loc[:, 'Mean'].to_list()),metric = f)),columns=df.index,index=df.index).values\n",
    "    Dist = Dist[r:,:r]\n",
    "    return Dist\n",
    "\n",
    "Dist = compute_dist(df_test,df_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la matriz de distancia, la linea negra separa neuron-noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7490d02d32df4724bd9627413d99c6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f1d0cd13710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(Dist)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una matriz de distancias. Cada fila representa la distancia de un template test a cada uno de los templates de train. Computamos el minimo, y nos fijamos si es neuron o noise, entonces asignamos ese valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_votes = 1\n",
    "Minn = [np.argsort(i)[:number_votes] for i in Dist[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(lista,t):\n",
    "    label = np.zeros(len(lista),dtype = int)\n",
    "    votes = len(lista[0])\n",
    "    for i,element in enumerate(lista):\n",
    "        votes_noise = len(np.where(element > t)[0])\n",
    "        if votes_noise >= int(votes/2) + 1: label[i] = 1\n",
    "    return label\n",
    "\n",
    "label = create_label(Minn,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons as noise =  67.70428015564202 (174)\n",
      "Noise found =  89.81636060100166 (538)\n"
     ]
    }
   ],
   "source": [
    "neurons = label[:t2]\n",
    "noises = label[t2:]\n",
    "\n",
    "total_neurons = len(neurons)\n",
    "total_noises = len(noises)\n",
    "neurons_as_noise = sum(neurons)\n",
    "noises_found = sum(noises)\n",
    "\n",
    "print('neurons as noise = ',neurons_as_noise/total_neurons*100,'({})'.format(neurons_as_noise))\n",
    "print('Noise found = ', noises_found/total_noises*100, '({})'.format(noises_found))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_time(number_votes = 3):\n",
    "    df_train,df_test,t2,t = Train_test_noise(data)\n",
    "    Dist = compute_dist(df_test,df_train)\n",
    "    Minn = [np.argsort(i)[:number_votes] for i in Dist[:]]\n",
    "    label = create_label(Minn,t)\n",
    "    neurons = label[:t2]\n",
    "    noises = label[t2:]\n",
    "\n",
    "    total_neurons = len(neurons)\n",
    "    print('total neurons in test = ',total_neurons,'. This represents ', total_neurons/len(label)*100,' of the test size')\n",
    "    total_noises = len(noises)\n",
    "    print('total neurons in test = ',total_noises,'. This represents ', total_noises/len(label)*100,' of the test size')\n",
    "\n",
    "    \n",
    "    total_found = sum(label)\n",
    "    print( 'The algorithm labeled ',total_found, 'clusters as noise')\n",
    "    \n",
    "    neurons_as_noise = sum(neurons)\n",
    "    print('The algorithm incorrectely labeled',round(neurons_as_noise/total_found*100,2), 'of the test (falses_positives)')\n",
    "    noises_found = sum(noises)\n",
    "    print('The algorithm correctely labeled',round(noises_found/total_found*100,2), 'of the test (True Noises)')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('\\n')\n",
    "    \n",
    "    falses_positives = neurons_as_noise/total_found\n",
    "    noise_found = noises_found/total_noises\n",
    "    \n",
    "    return falses_positives,noise_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total neurons in test =  197 . This represents  18.797709923664122  of the test size\n",
      "total neurons in test =  851 . This represents  81.20229007633588  of the test size\n",
      "The algorithm labeled  488 clusters as noise\n",
      "The algorithm incorrectely labeled 5.12 of the test (falses_positives)\n",
      "The algorithm correctely labeled 94.88 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  209 . This represents  21.976866456361723  of the test size\n",
      "total neurons in test =  742 . This represents  78.02313354363828  of the test size\n",
      "The algorithm labeled  670 clusters as noise\n",
      "The algorithm incorrectely labeled 18.21 of the test (falses_positives)\n",
      "The algorithm correctely labeled 81.79 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  239 . This represents  32.47282608695652  of the test size\n",
      "total neurons in test =  497 . This represents  67.52717391304348  of the test size\n",
      "The algorithm labeled  595 clusters as noise\n",
      "The algorithm incorrectely labeled 26.89 of the test (falses_positives)\n",
      "The algorithm correctely labeled 73.11 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  150 . This represents  15.274949083503056  of the test size\n",
      "total neurons in test =  832 . This represents  84.72505091649694  of the test size\n",
      "The algorithm labeled  752 clusters as noise\n",
      "The algorithm incorrectely labeled 14.76 of the test (falses_positives)\n",
      "The algorithm correctely labeled 85.24 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  220 . This represents  21.73913043478261  of the test size\n",
      "total neurons in test =  792 . This represents  78.26086956521739  of the test size\n",
      "The algorithm labeled  728 clusters as noise\n",
      "The algorithm incorrectely labeled 20.6 of the test (falses_positives)\n",
      "The algorithm correctely labeled 79.4 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  245 . This represents  32.666666666666664  of the test size\n",
      "total neurons in test =  505 . This represents  67.33333333333333  of the test size\n",
      "The algorithm labeled  606 clusters as noise\n",
      "The algorithm incorrectely labeled 26.57 of the test (falses_positives)\n",
      "The algorithm correctely labeled 73.43 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  229 . This represents  23.439099283520985  of the test size\n",
      "total neurons in test =  748 . This represents  76.56090071647903  of the test size\n",
      "The algorithm labeled  771 clusters as noise\n",
      "The algorithm incorrectely labeled 22.31 of the test (falses_positives)\n",
      "The algorithm correctely labeled 77.69 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  163 . This represents  16.90871369294606  of the test size\n",
      "total neurons in test =  801 . This represents  83.09128630705395  of the test size\n",
      "The algorithm labeled  704 clusters as noise\n",
      "The algorithm incorrectely labeled 16.62 of the test (falses_positives)\n",
      "The algorithm correctely labeled 83.38 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  153 . This represents  13.896457765667575  of the test size\n",
      "total neurons in test =  948 . This represents  86.10354223433242  of the test size\n",
      "The algorithm labeled  242 clusters as noise\n",
      "The algorithm incorrectely labeled 10.74 of the test (falses_positives)\n",
      "The algorithm correctely labeled 89.26 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "total neurons in test =  243 . This represents  30.186335403726712  of the test size\n",
      "total neurons in test =  562 . This represents  69.8136645962733  of the test size\n",
      "The algorithm labeled  499 clusters as noise\n",
      "The algorithm incorrectely labeled 31.26 of the test (falses_positives)\n",
      "The algorithm correctely labeled 68.74 of the test (True Noises)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "falses_positives_list = []\n",
    "noise_found_list= []\n",
    "for key in range(10):\n",
    "    a,b =  do_one_time(number_votes=1)\n",
    "    falses_positives_list.append(a)\n",
    "    noise_found_list.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19308968791179937 pm 0.07533078871019688\n",
      "0.6911085061854604 pm 0.1834694741537371\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(falses_positives_list),'pm',np.std(falses_positives_list))\n",
    "print(np.mean(noise_found_list),'pm',np.std(noise_found_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
