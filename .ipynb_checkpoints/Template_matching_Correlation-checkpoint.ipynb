{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "%matplotlib widget\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import matplotlib.cm as cm\n",
    "from Funciones_auxiliares import Mat_to_dataframe,see_teams,get_cluster_indexs,plot_branch,plot_teams,find_mix\n",
    "from scipy import cluster\n",
    "\n",
    "import scipy as sp\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importamos la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b7c6cde2aa54450b1ea71c33ff578ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close('all')\n",
    "plt.clf()\n",
    "plt.close()\n",
    "data = pd.read_pickle('Datos/PCCIBNMZc')\n",
    "data['Mean'] = data.Bulk.apply(lambda row: np.mean(row,axis = 0))\n",
    "data['Mean'] = (data['Mean'] - data.Mean.apply(lambda row:np.mean(row)))/data.Mean.apply(lambda row:np.std(row))\n",
    "del data['Bulk']\n",
    "Initial = len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separamos en Test y Train por sessiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113\n",
      "204\n",
      "248\n",
      "214\n",
      "55\n",
      "152\n",
      "170\n",
      "179\n",
      "131\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "Sessions_list = data.PatientExperiment.unique()\n",
    "select_random_sessions = np.random.choice(Sessions_list,(10,6), replace = False)\n",
    "Dfs = {}\n",
    "for i,sessions in enumerate(select_random_sessions):\n",
    "    Dfs[i] = data[data.PatientExperiment.isin(sessions)]\n",
    "for key,values in Dfs.items():\n",
    "    print(len(values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos la matriz de correlacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No tengo que entrenar nada, asumimos que el template matching para train es perfecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = Train.copy()\n",
    "df_test = Test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distancia Euclidea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train_test_noise(data):\n",
    "    Sessions_list = data.PatientExperiment.unique()\n",
    "    select_random_sessions = np.random.randint(0, len(Sessions_list), size=int(len(Sessions_list)/2))\n",
    "    Train_list = Sessions_list[select_random_sessions]\n",
    "    Train = data[data.PatientExperiment.isin(Train_list)]\n",
    "    Test = data[~data.PatientExperiment.isin(Train_list)]\n",
    "    Train.reset_index(inplace = True,drop = True)\n",
    "    Test.reset_index(inplace = True,drop = True)\n",
    "    \n",
    "    df_train = Train.copy()\n",
    "    df_test = Test.copy()\n",
    "    \n",
    "    Noise = df_train[df_train.bNoise == 1]\n",
    "    Neuron = df_train[df_train.bNoise == 0]\n",
    "    MU = df_train[df_train.bNoise == 2]\n",
    "\n",
    "    df_train = pd.concat([Neuron,MU,Noise], ignore_index= True, sort = False)\n",
    "    t = df_train[df_train.bNoise == 1].index[0]\n",
    "\n",
    "    Noise = df_test[df_test.bNoise == 1]\n",
    "    Neuron = df_test[df_test.bNoise == 0]\n",
    "    MU = df_test[df_test.bNoise == 2]\n",
    "\n",
    "    df_test = pd.concat([Neuron,MU,Noise], ignore_index= True, sort = False)\n",
    "    t2 = df_test[df_test.bNoise == 1].index[0]\n",
    "\n",
    "    \n",
    "    return df_test,df_test,t2,t\n",
    "\n",
    "df_train,df_test,t2,t = Train_test_noise(Dfs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Testeamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "def compute_dist(df_test,df_train):\n",
    "    df = pd.concat([df_train,df_test],ignore_index=True,sort = True)\n",
    "    r = len(df_train)\n",
    "    s = len(df_test)\n",
    "    Dist = pd.DataFrame(squareform(pdist(np.array(df.loc[:, 'Mean'].to_list()))),columns=df.index,index=df.index).values\n",
    "    Dist = Dist[r:,:s]\n",
    "    return Dist\n",
    "\n",
    "Dist = compute_dist(df_test,df_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos la matriz de distancia, la linea negra separa neuron-noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c503b6445e8c45c4bf076402b4fbda93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7f5ab4112e50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(Dist)\n",
    "plt.colorbar()\n",
    "plt.hlines(t2,0,Dist-1)\n",
    "plt.vlines(t,0,Dist-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una matriz de distancias. Cada fila representa la distancia de un template test a cada uno de los templates de train. Computamos el minimo, y nos fijamos si es neuron o noise, entonces asignamos ese valor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_votes = 3\n",
    "Minn = [np.argsort(i)[:number_votes] for i in Dist[:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label(lista,t):\n",
    "    label = np.zeros(len(lista),dtype = int)\n",
    "    votes = len(lista[0])\n",
    "    for i,element in enumerate(lista):\n",
    "        votes_noise = len(np.where(element > t)[0])\n",
    "        if votes_noise >= int(votes/2) + 1: label[i] = 1\n",
    "    return label\n",
    "\n",
    "label = create_label(Minn,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neurons as noise =  31.818181818181817 (7)\n",
      "Noise found =  97.05882352941177 (33)\n"
     ]
    }
   ],
   "source": [
    "neurons = label[:t2]\n",
    "noises = label[t2:]\n",
    "\n",
    "total_neurons = len(neurons)\n",
    "total_noises = len(noises)\n",
    "neurons_as_noise = sum(neurons)\n",
    "noises_found = sum(noises)\n",
    "\n",
    "print('neurons as noise = ',neurons_as_noise/total_neurons*100,'({})'.format(neurons_as_noise))\n",
    "print('Noise found = ', noises_found/total_noises*100, '({})'.format(noises_found))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_one_time(number_votes = 3):\n",
    "    df_train,df_test,t2,t = Train_test_noise(data)\n",
    "    Dist = compute_dist(df_test,df_train)\n",
    "    Minn = [np.argsort(i)[:number_votes] for i in Dist[:]]\n",
    "    label = create_label(Minn,t)\n",
    "    neurons = label[:t2]\n",
    "    noises = label[t2:]\n",
    "\n",
    "    total_neurons = len(neurons)\n",
    "    total_noises = len(noises)\n",
    "    \n",
    "    neurons_as_noise = sum(neurons)\n",
    "    noises_found = sum(noises)\n",
    "    \n",
    "    return noises_found/total_noises,neurons_as_noise/total_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons_as_noise_list = []\n",
    "noises_found_list = []\n",
    "for key in Dfs:\n",
    "    a,b =  do_one_time(number_votes=1)\n",
    "    neurons_as_noise_list.append(b)\n",
    "    noises_found_list.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47167055324106955 pm 0.22588977019699932\n",
      "0.9860950425832069 pm 0.005353673129195264\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(neurons_as_noise_list),'pm',np.std(neurons_as_noise_list))\n",
    "print(np.mean(noises_found_list),'pm',np.std(noises_found_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
